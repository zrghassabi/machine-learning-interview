{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMhwV25tTSMUXeVDwIG5vJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/machine-learning-interview/blob/main/ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "k-means from scratch"
      ],
      "metadata": {
        "id": "xdHcqIr1Otbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def initialize_centroids(X, k):\n",
        "    \"\"\"Randomly initialize centroids from the dataset.\"\"\"\n",
        "    np.random.seed(42)  # for reproducibility\n",
        "    random_indices = np.random.permutation(X.shape[0])\n",
        "    centroids = X[random_indices[:k]]\n",
        "    return centroids\n",
        "\n",
        "def compute_distances(X, centroids):\n",
        "    \"\"\"Calculate the distance between each point in X and each centroid.\"\"\"\n",
        "    distances = np.zeros((X.shape[0], len(centroids)))\n",
        "    for i, centroid in enumerate(centroids):\n",
        "        distances[:, i] = np.linalg.norm(X - centroid, axis=1)\n",
        "    return distances\n",
        "\n",
        "def assign_clusters(distances):\n",
        "    \"\"\"Assign each data point to the nearest centroid.\"\"\"\n",
        "    return np.argmin(distances, axis=1)\n",
        "\n",
        "def update_centroids(X, labels, k):\n",
        "    \"\"\"Update the centroid of each cluster to the mean of the assigned points.\"\"\"\n",
        "    new_centroids = np.zeros((k, X.shape[1]))\n",
        "    for i in range(k):\n",
        "        cluster_points = X[labels == i]\n",
        "        if len(cluster_points) > 0:\n",
        "            new_centroids[i] = cluster_points.mean(axis=0)\n",
        "    return new_centroids\n",
        "\n",
        "def k_means(X, k, max_iters=100):\n",
        "    \"\"\"Run the K-Means algorithm.\"\"\"\n",
        "    # Step 1: Initialize centroids\n",
        "    centroids = initialize_centroids(X, k)\n",
        "\n",
        "    for iteration in range(max_iters):\n",
        "        # Step 2: Compute distances and assign clusters\n",
        "        distances = compute_distances(X, centroids)\n",
        "        labels = assign_clusters(distances)\n",
        "\n",
        "        # Step 3: Update centroids\n",
        "        new_centroids = update_centroids(X, labels, k)\n",
        "\n",
        "        # Step 4: Check for convergence (if centroids do not change)\n",
        "        if np.all(centroids == new_centroids):\n",
        "            break\n",
        "\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return centroids, labels\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate synthetic data using sklearn\n",
        "    from sklearn.datasets import make_blobs\n",
        "    X, y = make_blobs(n_samples=300, centers=3, random_state=42)\n",
        "\n",
        "    # Apply K-Means algorithm\n",
        "    k = 3\n",
        "    centroids, labels = k_means(X, k)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o', edgecolor='k')\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', marker='X')\n",
        "    plt.title('K-Means Clustering Results')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LHmyCHuiUTZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yyPIN2jie_XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression from scratch"
      ],
      "metadata": {
        "id": "KBNZh00Ee_--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Linear Regression implementation\n",
        "def predict(X, weights, bias):\n",
        "    \"\"\"Predict the output for the given input X using learned weights and bias.\"\"\"\n",
        "    return np.dot(X, weights) + bias\n",
        "\n",
        "def compute_loss(y_true, y_pred):\n",
        "    \"\"\"Compute Mean Squared Error (MSE) as the loss function.\"\"\"\n",
        "    n_samples = len(y_true)\n",
        "    return (1 / n_samples) * np.sum((y_pred - y_true) ** 2)\n",
        "\n",
        "def gradient_descent(X, y, weights, bias, learning_rate):\n",
        "    \"\"\"Perform one step of gradient descent to update weights and bias.\"\"\"\n",
        "    n_samples = len(y)\n",
        "\n",
        "    # Calculate predictions\n",
        "    y_pred = predict(X, weights, bias)\n",
        "\n",
        "    # Calculate gradients\n",
        "    dW = (2 / n_samples) * np.dot(X.T, (y_pred - y))  # Gradient with respect to weights\n",
        "    db = (2 / n_samples) * np.sum(y_pred - y)  # Gradient with respect to bias\n",
        "\n",
        "    # Update weights and bias\n",
        "    weights -= learning_rate * dW\n",
        "    bias -= learning_rate * db\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "def train(X, y, learning_rate=0.01, n_iters=1000):\n",
        "    \"\"\"Train the Linear Regression model using gradient descent.\"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Initialize weights and bias\n",
        "    weights = np.zeros(n_features)\n",
        "    bias = 0\n",
        "\n",
        "    # Gradient descent loop\n",
        "    for i in range(n_iters):\n",
        "        # Perform a single step of gradient descent\n",
        "        weights, bias = gradient_descent(X, y, weights, bias, learning_rate)\n",
        "\n",
        "        # Compute loss every 100 iterations\n",
        "        if i % 100 == 0:\n",
        "            y_pred = predict(X, weights, bias)\n",
        "            loss = compute_loss(y, y_pred)\n",
        "            print(f\"Iteration {i}: Loss = {loss}\")\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create some random data\n",
        "    np.random.seed(42)\n",
        "    X = 2 * np.random.rand(100, 1)\n",
        "    y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "    # Train the model\n",
        "    weights, bias = train(X, y, learning_rate=0.01, n_iters=1000)\n",
        "\n",
        "    # Test the model\n",
        "    X_test = np.array([[1.5]])\n",
        "    prediction = predict(X_test, weights, bias)\n",
        "    print(f\"Prediction for input {X_test}: {prediction}\")\n"
      ],
      "metadata": {
        "id": "blEKSGj1PZXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Prediction function for a single data point\n",
        "def predict_single(x, weights, bias):\n",
        "    \"\"\"Predict the output for a single data point using learned weights and bias.\"\"\"\n",
        "    y_pred = 0\n",
        "    for i in range(len(weights)):\n",
        "        y_pred += weights[i] * x[i]\n",
        "    return y_pred + bias\n",
        "\n",
        "# Loss function (Mean Squared Error)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    \"\"\"Compute Mean Squared Error (MSE) for a single prediction.\"\"\"\n",
        "    return (y_true - y_pred) ** 2\n",
        "\n",
        "# Gradient descent for one step (updating weights and bias)\n",
        "def gradient_descent(X, y, weights, bias, learning_rate):\n",
        "    \"\"\"Perform one step of gradient descent to update weights and bias.\"\"\"\n",
        "    n_samples = len(y)\n",
        "\n",
        "    # Initialize gradients\n",
        "    dW = np.zeros(len(weights))\n",
        "    db = 0\n",
        "\n",
        "    # Compute gradients manually for each point\n",
        "    for i in range(n_samples):\n",
        "        y_pred = predict_single(X[i], weights, bias)\n",
        "        error = y_pred - y[i]\n",
        "\n",
        "        # Update gradients for each weight and bias\n",
        "        for j in range(len(weights)):\n",
        "            dW[j] += (2 / n_samples) * error * X[i][j]\n",
        "        db += (2 / n_samples) * error\n",
        "\n",
        "    # Update weights and bias\n",
        "    for j in range(len(weights)):\n",
        "        weights[j] -= learning_rate * dW[j]\n",
        "    bias -= learning_rate * db\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# Training function for Linear Regression\n",
        "def train(X, y, learning_rate=0.01, n_iters=1000):\n",
        "    \"\"\"Train the Linear Regression model using gradient descent.\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "82SDEcbofC9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Compute the Intersection over Union (IoU) of two bounding boxes.\n",
        "\n",
        "    Parameters:\n",
        "    box1: list or array of coordinates [x1, y1, x2, y2]\n",
        "    box2: list or array of coordinates [x1, y1, x2, y2]\n",
        "\n",
        "    Returns:\n",
        "    float: IoU score\n",
        "    \"\"\"\n",
        "    # Get the coordinates of the intersection rectangle\n",
        "    x_left = max(box1[0], box2[0])\n",
        "    y_top = max(box1[1], box2[1])\n",
        "    x_right = min(box1[2], box2[2])\n",
        "    y_bottom = min(box1[3], box2[3])\n",
        "\n",
        "    # Compute the area of intersection\n",
        "    intersection_area = max(0, x_right - x_left) * max(0, y_bottom - y_top)\n",
        "\n",
        "    # Compute the area of both bounding boxes\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    # Compute the area of union\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Compute IoU\n",
        "    iou = intersection_area / union_area if union_area != 0 else 0\n",
        "\n",
        "    return iou\n"
      ],
      "metadata": {
        "id": "l7WEidArh_c5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}